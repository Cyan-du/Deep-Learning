{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MULTI LAYER PERCEPTRON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is for a Multilayer perceptron.I have used feed forward,gradient descent and error backpropagation algorithm to model the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list of activation functions\n",
    "def sigmoid(x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "def linear(x):\n",
    "        return x\n",
    "def tanh(x):\n",
    "        return ((np.exp(2*x)-1)/(np.exp(2*x)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    #initialising the dataset\n",
    "    def __init__(self,inodes,hnodes,onodes,h_actf,o_actf):\n",
    "        self.inodes = inodes\n",
    "        self.hnodes = hnodes\n",
    "        self.onodes = onodes\n",
    "        self.h_actf = h_actf\n",
    "        self.o_actf = o_actf\n",
    "        self.input_weights = np.random.random((hnodes,inodes))\n",
    "        self.hidden_weights = np.random.random((onodes,hnodes))\n",
    "    #training the dataset\n",
    "    def train(self,data,eta,epoch):\n",
    "        for i in range(epoch):\n",
    "            for i in range(len(data.index)):\n",
    "                #setting the input and target values\n",
    "                inputs=np.array(data.ix[i][:self.inodes]).reshape((self.inodes,1))\n",
    "                targets=np.array(data.ix[i,self.inodes:]).reshape((self.onodes,1))\n",
    "                #finding the outputs of hidden layer\n",
    "                if self.h_actf=='sigmoid':\n",
    "                    hidden_outputs=sigmoid(np.dot(self.input_weights,inputs))\n",
    "                elif self.h_actf=='tanh':\n",
    "                    hidden_outputs=tanh(np.dot(self.input_weights,inputs))\n",
    "                elif self.h_actf=='linear':\n",
    "                    hidden_outputs=linear(np.dot(self.input_weights,inputs))\n",
    "                #finding the outputs of target layer\n",
    "                if self.o_actf=='sigmoid':\n",
    "                    final_outputs=sigmoid(np.dot(self.hidden_weights,hidden_outputs))\n",
    "                elif self.o_actf=='tanh':\n",
    "                    final_outputs=tanh(np.dot(self.hidden_weights,hidden_outputs))\n",
    "                elif self.o_actf=='linear':\n",
    "                    final_outputs=linear(np.dot(self.hidden_weights,hidden_outputs))\n",
    "                #errors of target and hidden layer\n",
    "                error_target = targets - final_outputs\n",
    "                error_hidden = np.dot(np.transpose(self.hidden_weights),error_target)\n",
    "                #updating the weights of hidden_target layer\n",
    "                if self.o_actf=='sigmoid':\n",
    "                    self.hidden_weights += eta*np.dot((error_target*final_outputs*(1-final_outputs)),np.transpose(hidden_outputs))\n",
    "                elif self.o_actf=='tanh':\n",
    "                    self.hidden_weights += eta*np.dot((error_target*(1-final_outputs**2)),np.transpose(hidden_outputs))\n",
    "                elif self.o_actf=='linear':\n",
    "                    self.hidden_weights += eta*np.dot(error_target,np.transpose(hidden_outputs))\n",
    "                #updating the weights of input_hidden layer\n",
    "                if self.h_actf=='sigmoid':\n",
    "                    self.input_weights += eta*np.dot((error_hidden*hidden_outputs*(1-hidden_outputs)),np.transpose(inputs))\n",
    "                elif self.h_actf=='tanh':\n",
    "                    self.input_weights += eta*np.dot((error_hidden*(1-hidden_outputs**2)),np.transpose(inputs))\n",
    "                elif self.h_actf=='linear':\n",
    "                    self.input_weights += eta*np.dot(error_hidden,np.transpose(inputs))\n",
    "    #testing the dataset           \n",
    "    def test(self,data,problem):\n",
    "        classify=[]\n",
    "        for i in range(len(data.index)):\n",
    "                inputs=np.array(data.ix[i][:self.inodes]).reshape((self.inodes,1))\n",
    "                #finding the outputs of hidden layer\n",
    "                if self.h_actf=='sigmoid':\n",
    "                    hidden_outputs=sigmoid(np.dot(self.input_weights,inputs))\n",
    "                elif self.h_actf=='tanh':\n",
    "                    hidden_outputs=tanh(np.dot(self.input_weights,inputs))\n",
    "                elif self.h_actf=='linear':\n",
    "                    hidden_outputs=linear(np.dot(self.input_weights,inputs))\n",
    "                #finding the outputs of target layer\n",
    "                if self.o_actf=='sigmoid':\n",
    "                    final_outputs=sigmoid(np.dot(self.hidden_weights,hidden_outputs))\n",
    "                elif self.o_actf=='tanh':\n",
    "                    final_outputs=tanh(np.dot(self.hidden_weights,hidden_outputs))\n",
    "                elif self.o_actf=='linear':\n",
    "                    final_outputs=linear(np.dot(self.hidden_weights,hidden_outputs))\n",
    "                #output for a classification problem\n",
    "                if problem =='classification':\n",
    "                    #print('output is',np.argmax(final_outputs))\n",
    "                    classify.append(np.argmax(final_outputs))\n",
    "                #output for a regression problem\n",
    "                if problem == 'regression':\n",
    "                    #print('output is',final_outputs[0])\n",
    "                    classify.append(final_outputs[0])\n",
    "        return classify   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input1</th>\n",
       "      <th>input2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   input1  input2  target\n",
       "0       0       0       0\n",
       "1       0       1       1\n",
       "2       1       0       1\n",
       "3       1       1       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##creating a data for XOR gate\n",
    "xor_gate=DataFrame(np.array([[0,0,0],[0,1,1],[1,0,1],[1,1,0]]),columns=['input1','input2','target'])\n",
    "xor_gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input1</th>\n",
       "      <th>input2</th>\n",
       "      <th>target_0</th>\n",
       "      <th>target_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   input1  input2  target_0  target_1\n",
       "0       0       0         1         0\n",
       "1       0       1         0         1\n",
       "2       1       0         0         1\n",
       "3       1       1         1         0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##transforming the data for XOR gate to feed into the MLP\n",
    "xor_gate=DataFrame(np.array([[0,0,1,0],[0,1,0,1],[1,0,0,1],[1,1,1,0]]),columns=['input1','input2','target_0','target_1'])\n",
    "xor_gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialising and training the data\n",
    "p = MLP(2,2,2,'tanh','tanh')\n",
    "p.train(xor_gate,0.25,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing the data\n",
    "p.test(xor_gate,'classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output seems to match with the target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#classifying the iris dataset\n",
    "#I have already splitted the dataset into training,validation and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('C:/Users/HP/Desktop/datasets/training.csv')\n",
    "test=pd.read_csv('C:/Users/HP/Desktop/datasets/testing.csv')\n",
    "validate=pd.read_csv('C:/Users/HP/Desktop/datasets/validate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the species column\n",
    "train_final=train.drop('Species',axis=1)\n",
    "test_final=test.drop('Species',axis=1)\n",
    "validate_final=validate.drop('Species',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialising and training the network\n",
    "p = MLP(4,4,3,'sigmoid','sigmoid')\n",
    "p.train(train_final,0.3,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8947368421052632"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy for validation set\n",
    "x=p.test(validate_final,'classification')\n",
    "cls=x\n",
    "count=0\n",
    "for i in range(len(x)):\n",
    "    if x[i]==0:\n",
    "        cls[i]='setosa'\n",
    "    elif x[i]==1:\n",
    "        cls[i]='versicolor'\n",
    "    else:\n",
    "        cls[i]='virginica'\n",
    "orig=validate['Species'].values\n",
    "for i in range(len(orig)):\n",
    "    if orig[i]==cls[i]:\n",
    "        count +=1\n",
    "accuracy=count/len(orig)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7027027027027027"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy for testing dataset\n",
    "x=p.test(test_final,'classification')\n",
    "cls=x\n",
    "count=0\n",
    "for i in range(len(x)):\n",
    "    if x[i]==0:\n",
    "        cls[i]='setosa'\n",
    "    elif x[i]==1:\n",
    "        cls[i]='versicolor'\n",
    "    else:\n",
    "        cls[i]='virginica'\n",
    "orig=test['Species'].values\n",
    "for i in range(len(orig)):\n",
    "    if orig[i]==cls[i]:\n",
    "        count +=1\n",
    "accuracy=count/len(orig)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of improvement needs to be done on our MLP model,like tuning the learning rate,epochs or adjusting the \n",
    "no of hidden nodes.There are ways to find the optimal values of these parameters which is a topic for some other time.\n",
    "But for now you can try by changing the activation functions and see how the accuracy changes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
