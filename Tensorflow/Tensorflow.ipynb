{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and running a tensorflow session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assigning a variable in the computational graph and then running the session\n",
    "x = tf.Variable(3,name='x')\n",
    "y = tf.Variable(4,name='y')\n",
    "f = x*x*y + y + 2\n",
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "sess.run(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assignning using constant doesnot require placing the values in the computation graph\n",
    "x = tf.constant(3)\n",
    "y = tf.constant(4)\n",
    "f = x*x*y + y + 2\n",
    "sess = tf.Session()\n",
    "sess.run(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using global variables_initializer() and InteractiveSession()\n",
    "x = tf.Variable(3,name='x')\n",
    "y = tf.Variable(4,name='y')\n",
    "f = x*x*y + y + 2\n",
    "init = tf.global_variables_initializer() #prepare an init node\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "sess.run(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using global variables_initializer() and Session()\n",
    "x = tf.Variable(3,name='x')\n",
    "y = tf.Variable(4,name='y')\n",
    "f = x*x*y + y + 2\n",
    "init = tf.global_variables_initializer() #creating a node in the graph\n",
    "sess = tf.Session()\n",
    "sess.run(init)#initialising all the variables\n",
    "sess.run(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Anything that we create is automatically added to the default graph\n",
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#creating independent graph\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "print(x2.graph is graph)\n",
    "print(x2.graph is tf.get_default_graph() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Life cycle of a Node value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x + 3\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(y))\n",
    "    print(sess.run(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1         2         3       4         5      6       7\n",
       "0  8.3252  41.0  6.984127  1.023810   322.0  2.555556  37.88 -122.23\n",
       "1  8.3014  21.0  6.238137  0.971880  2401.0  2.109842  37.86 -122.22\n",
       "2  7.2574  52.0  8.288136  1.073446   496.0  2.802260  37.85 -122.24\n",
       "3  5.6431  52.0  5.817352  1.073059   558.0  2.547945  37.85 -122.25\n",
       "4  3.8462  52.0  6.281853  1.081081   565.0  2.181467  37.85 -122.25"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = pd.read_csv('regression.csv')\n",
    "housing = housing.drop(['Unnamed: 0'],axis=1)\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_labels = pd.read_csv('targets.csv')\n",
    "housing_labels = housing_labels.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_labels = np.array(housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = np.array(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,n = housing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_adding_bias = np.c_[np.ones((m,1)),housing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.constant(housing_adding_bias,dtype=tf.float64,name=\"X\")\n",
    "y = tf.constant(housing_labels,dtype=tf.float64,name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT,X)),XT),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.69419202e+01],\n",
       "       [ 4.36693293e-01],\n",
       "       [ 9.43577803e-03],\n",
       "       [-1.07322041e-01],\n",
       "       [ 6.45065694e-01],\n",
       "       [-3.97638942e-06],\n",
       "       [-3.78654265e-03],\n",
       "       [-4.21314378e-01],\n",
       "       [-4.34513755e-01]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.69419202e+01],\n",
       "       [ 4.36693293e-01],\n",
       "       [ 9.43577803e-03],\n",
       "       [-1.07322041e-01],\n",
       "       [ 6.45065694e-01],\n",
       "       [-3.97638942e-06],\n",
       "       [-3.78654265e-03],\n",
       "       [-4.21314378e-01],\n",
       "       [-4.34513755e-01]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Comparing with numpy\n",
    "X = housing_adding_bias\n",
    "y = housing_labels\n",
    "theta_numpy = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "theta_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Manually computing the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "housing_std = scaler.fit_transform(housing)\n",
    "std_housing_add_bias = np.c_[np.ones((m,1)),housing_std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 2.7544262\n",
      "Epoch 100 MSE = 0.632222\n",
      "Epoch 200 MSE = 0.5727805\n",
      "Epoch 300 MSE = 0.5585007\n",
      "Epoch 400 MSE = 0.54907\n",
      "Epoch 500 MSE = 0.542288\n",
      "Epoch 600 MSE = 0.53737885\n",
      "Epoch 700 MSE = 0.533822\n",
      "Epoch 800 MSE = 0.5312425\n",
      "Epoch 900 MSE = 0.5293705\n"
     ]
    }
   ],
   "source": [
    "#implementing batch gradient descent\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(std_housing_add_bias,dtype=tf.float32,name=\"X\")\n",
    "y = tf.constant(housing_labels,dtype=tf.float32,name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0,seed=42),name='theta')#tf.random_uniform works same like np.random.rand()\n",
    "y_pred = tf.matmul(X,theta,name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error),name='mse')#tf.reduce_mean finds the mean\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X),error)\n",
    "training_op = tf.assign(theta,theta - learning_rate * gradients)#tf.assign()creates a node that will assign a new value to theta\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", sess.run(mse))\n",
    "        sess.run(training_op)\n",
    "    \n",
    "best_theta = sess.run(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.06855226e+00],\n",
       "       [ 7.74078071e-01],\n",
       "       [ 1.31192386e-01],\n",
       "       [-1.17845066e-01],\n",
       "       [ 1.64778143e-01],\n",
       "       [ 7.44081801e-04],\n",
       "       [-3.91945131e-02],\n",
       "       [-8.61356556e-01],\n",
       "       [-8.23479712e-01]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Using autodiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 2.7544262\n",
      "Epoch 100 MSE = 0.632222\n",
      "Epoch 200 MSE = 0.5727805\n",
      "Epoch 300 MSE = 0.5585007\n",
      "Epoch 400 MSE = 0.54907\n",
      "Epoch 500 MSE = 0.54228795\n",
      "Epoch 600 MSE = 0.5373789\n",
      "Epoch 700 MSE = 0.533822\n",
      "Epoch 800 MSE = 0.5312425\n",
      "Epoch 900 MSE = 0.5293704\n"
     ]
    }
   ],
   "source": [
    "#implementing batch gradient descent\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(std_housing_add_bias,dtype=tf.float32,name=\"X\")\n",
    "y = tf.constant(housing_labels,dtype=tf.float32,name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0,seed=42),name='theta')#tf.random_uniform works same like np.random.rand()\n",
    "y_pred = tf.matmul(X,theta,name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error),name='mse')#tf.reduce_mean finds the mean\n",
    "gradients = tf.gradients(mse,[theta])[0]# instead of 2/m * tf.matmul(tf.transpose(X),error)\n",
    "training_op = tf.assign(theta,theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", sess.run(mse))\n",
    "        sess.run(training_op)\n",
    "    \n",
    "best_theta = sess.run(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.06855249e+00],\n",
       "       [ 7.74078071e-01],\n",
       "       [ 1.31192386e-01],\n",
       "       [-1.17845066e-01],\n",
       "       [ 1.64778143e-01],\n",
       "       [ 7.44078017e-04],\n",
       "       [-3.91945094e-02],\n",
       "       [-8.61356676e-01],\n",
       "       [-8.23479772e-01]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.Using an Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 2.7544262\n",
      "Epoch 100 MSE = 0.632222\n",
      "Epoch 200 MSE = 0.5727805\n",
      "Epoch 300 MSE = 0.5585007\n",
      "Epoch 400 MSE = 0.54907\n",
      "Epoch 500 MSE = 0.54228795\n",
      "Epoch 600 MSE = 0.5373789\n",
      "Epoch 700 MSE = 0.533822\n",
      "Epoch 800 MSE = 0.5312425\n",
      "Epoch 900 MSE = 0.5293704\n"
     ]
    }
   ],
   "source": [
    "#implementing batch gradient descent\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(std_housing_add_bias,dtype=tf.float32,name=\"X\")\n",
    "y = tf.constant(housing_labels,dtype=tf.float32,name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0,seed=42),name='theta')#tf.random_uniform works same like np.random.rand()\n",
    "y_pred = tf.matmul(X,theta,name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error),name='mse')#tf.reduce_mean finds the mean\n",
    "#gradients = tf.gradients(mse,[theta])[0]# instead of 2/m * tf.matmul(tf.transpose(X),error)\n",
    "#training_op = tf.assign(theta,theta - learning_rate * gradients)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", sess.run(mse))\n",
    "        sess.run(training_op)\n",
    "    \n",
    "best_theta = sess.run(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using placeholders to train mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6. 7. 8.]]\n",
      "[[ 9. 10. 11.]\n",
      " [12. 13. 14.]]\n"
     ]
    }
   ],
   "source": [
    "#creating placeholders\n",
    "A = tf.placeholder(tf.float32,shape=(None,3))\n",
    "B = A + 5\n",
    "print(sess.run(B,feed_dict={A:[[1,2,3]]}))\n",
    "print(sess.run(B,feed_dict={A:[[4,5,6],[7,8,9]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing mini -batch gradient descent\n",
    "n_epochs = 10\n",
    "learning_rate = 0.01\n",
    "batch_size=100\n",
    "n_batches = int(np.ceil(m/batch_size))\n",
    "\n",
    "X = tf.placeholder(dtype=tf.float32,shape=(None,n+1),name=\"X\")\n",
    "y = tf.placeholder(dtype=tf.float32,shape=(None,1),name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0,seed=42),name='theta')#tf.random_uniform works same like np.random.rand()\n",
    "y_pred = tf.matmul(X,theta,name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error),name='mse')#tf.reduce_mean finds the mean\n",
    "#gradients = tf.gradients(mse,[theta])[0]# instead of 2/m * tf.matmul(tf.transpose(X),error)\n",
    "#training_op = tf.assign(theta,theta - learning_rate * gradients)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "#creating a function to get the minibatches\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index)  # not shown in the book\n",
    "    indices = np.random.randint(m, size=batch_size)  # not shown\n",
    "    X_batch = std_housing_add_bias[indices] # not shown\n",
    "    y_batch = housing_labels[indices] # not shown\n",
    "    return X_batch, y_batch\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "best_theta = sess.run(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.070016  ],\n",
       "       [ 0.8204561 ],\n",
       "       [ 0.1173173 ],\n",
       "       [-0.22739051],\n",
       "       [ 0.3113402 ],\n",
       "       [ 0.00353193],\n",
       "       [-0.01126994],\n",
       "       [-0.91643935],\n",
       "       [-0.8795008 ]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Restoring Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 2.7544262\n",
      "Epoch 100 MSE = 0.632222\n",
      "Epoch 200 MSE = 0.5727805\n",
      "Epoch 300 MSE = 0.5585007\n",
      "Epoch 400 MSE = 0.54907\n",
      "Epoch 500 MSE = 0.54228795\n",
      "Epoch 600 MSE = 0.5373789\n",
      "Epoch 700 MSE = 0.533822\n",
      "Epoch 800 MSE = 0.5312425\n",
      "Epoch 900 MSE = 0.5293704\n"
     ]
    }
   ],
   "source": [
    "#implementing batch gradient descent\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(std_housing_add_bias,dtype=tf.float32,name=\"X\")\n",
    "y = tf.constant(housing_labels,dtype=tf.float32,name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0,seed=42),name='theta')#tf.random_uniform works same like np.random.rand()\n",
    "y_pred = tf.matmul(X,theta,name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error),name='mse')#tf.reduce_mean finds the mean\n",
    "#gradients = tf.gradients(mse,[theta])[0]# instead of 2/m * tf.matmul(tf.transpose(X),error)\n",
    "#training_op = tf.assign(theta,theta - learning_rate * gradients)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "saver = tf.train.Saver()\n",
    "for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", sess.run(mse))\n",
    "            save_path = saver.save(sess, \"C:/Users/HP/Hands on Machine learning with sckitlearn and tensor flow/End to end ML project/gradientdescent.ckpt\")\n",
    "        sess.run(training_op)\n",
    "    \n",
    "best_theta = sess.run(theta)\n",
    "save_path = saver.save(sess, \"C:/Users/HP/Hands on Machine learning with sckitlearn and tensor flow/End to end ML project/gradientdescent.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.06855249e+00],\n",
       "       [ 7.74078071e-01],\n",
       "       [ 1.31192386e-01],\n",
       "       [-1.17845066e-01],\n",
       "       [ 1.64778143e-01],\n",
       "       [ 7.44078017e-04],\n",
       "       [-3.91945094e-02],\n",
       "       [-8.61356676e-01],\n",
       "       [-8.23479772e-01]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:/Users/HP/Hands on Machine learning with sckitlearn and tensor flow/End to end ML project/gradientdescent.ckpt\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "saver.restore(sess, \"C:/Users/HP/Hands on Machine learning with sckitlearn and tensor flow/End to end ML project/gradientdescent.ckpt\")\n",
    "best_theta_restored = sess.run(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.06855249e+00],\n",
       "       [ 7.74078071e-01],\n",
       "       [ 1.31192386e-01],\n",
       "       [-1.17845066e-01],\n",
       "       [ 1.64778143e-01],\n",
       "       [ 7.44078017e-04],\n",
       "       [-3.91945094e-02],\n",
       "       [-8.61356676e-01],\n",
       "       [-8.23479772e-01]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta_restored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(best_theta, best_theta_restored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 2.7544262\n",
      "Epoch 100 MSE = 0.632222\n",
      "Epoch 200 MSE = 0.5727805\n",
      "Epoch 300 MSE = 0.5585007\n",
      "Epoch 400 MSE = 0.54907\n",
      "Epoch 500 MSE = 0.54228795\n",
      "Epoch 600 MSE = 0.5373789\n",
      "Epoch 700 MSE = 0.533822\n",
      "Epoch 800 MSE = 0.5312425\n",
      "Epoch 900 MSE = 0.5293704\n"
     ]
    }
   ],
   "source": [
    "#saving and restoring a particular variable\n",
    "#implementing batch gradient descent\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(std_housing_add_bias,dtype=tf.float32,name=\"X\")\n",
    "y = tf.constant(housing_labels,dtype=tf.float32,name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0,seed=42),name='theta')#tf.random_uniform works same like np.random.rand()\n",
    "y_pred = tf.matmul(X,theta,name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error),name='mse')#tf.reduce_mean finds the mean\n",
    "#gradients = tf.gradients(mse,[theta])[0]# instead of 2/m * tf.matmul(tf.transpose(X),error)\n",
    "#training_op = tf.assign(theta,theta - learning_rate * gradients)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "saver = tf.train.Saver({'weights':theta})\n",
    "for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", sess.run(mse))\n",
    "            save_path = saver.save(sess, \"C:/Users/HP/Hands on Machine learning with sckitlearn and tensor flow/End to end ML project/gradientdescent.ckpt\")\n",
    "        sess.run(training_op)\n",
    "    \n",
    "best_theta = sess.run(theta)\n",
    "save_path = saver.save(sess, \"C:/Users/HP/Hands on Machine learning with sckitlearn and tensor flow/End to end ML project/gradientdescent.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.06855249e+00],\n",
       "       [ 7.74078071e-01],\n",
       "       [ 1.31192386e-01],\n",
       "       [-1.17845066e-01],\n",
       "       [ 1.64778143e-01],\n",
       "       [ 7.44078017e-04],\n",
       "       [-3.91945094e-02],\n",
       "       [-8.61356676e-01],\n",
       "       [-8.23479772e-01]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:/Users/HP/Hands on Machine learning with sckitlearn and tensor flow/End to end ML project/gradientdescent.ckpt\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "saver.restore(sess, \"C:/Users/HP/Hands on Machine learning with sckitlearn and tensor flow/End to end ML project/gradientdescent.ckpt\")\n",
    "best_theta_restored = sess.run(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.06855249e+00],\n",
       "       [ 7.74078071e-01],\n",
       "       [ 1.31192386e-01],\n",
       "       [-1.17845066e-01],\n",
       "       [ 1.64778143e-01],\n",
       "       [ 7.44078017e-04],\n",
       "       [-3.91945094e-02],\n",
       "       [-8.61356676e-01],\n",
       "       [-8.23479772e-01]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta_restored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(best_theta, best_theta_restored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression using tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv(\"iris.csv\")\n",
    "dat = iris[['SepalLength','SepalWidth','Name']]\n",
    "dat = dat.loc[dat['Name']!='Iris-virginica',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(dat.iloc[:,:-1])\n",
    "Y = np.where(dat['Name']=='Iris-setosa',1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self,n_epochs=1000,n_inputs=2,learning_rate=0.01):\n",
    "        self.epochs = n_epochs\n",
    "        self.lr = learning_rate\n",
    "        self.W = tf.Variable(np.random.randn(n_inputs,1), dtype=tf.float32,name = 'W')#shape = (n_inputs,1)\n",
    "        self.b = tf.Variable(tf.zeros(1), dtype=tf.float32,name='b')\n",
    "    def fit(self,x,Y):\n",
    "        X = tf.constant(x.T,dtype=tf.float32,name=\"X\")\n",
    "        y = tf.constant(Y.reshape(1,x.shape[0]),dtype=tf.float32,name=\"y\")\n",
    "        Z = tf.matmul(tf.transpose(self.W),X) + self.b\n",
    "        A = tf.sigmoid(Z)\n",
    "        #cost = tf.reduce_mean(-(y*tf.log(A)+(1-y)*tf.log(1-A)))\n",
    "        cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Z,  labels = y))\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate = self.lr)\n",
    "        training_op = optimizer.minimize(cost)\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess = tf.Session()\n",
    "        sess.run(init)\n",
    "        for epoch in range(self.epochs):\n",
    "            if epoch % 100 == 0:\n",
    "                print(\"Epoch\", epoch, \"cost =\", sess.run(cost))\n",
    "            sess.run(training_op)\n",
    "        self.W = sess.run(self.W)\n",
    "        self.b = sess.run(self.b)\n",
    "    def predict(self,x,threshold=0.5):\n",
    "        X_test = tf.constant(x.T,dtype=tf.float32,name=\"X_test\")\n",
    "        Z = tf.matmul(tf.transpose(self.W),X_test) + self.b\n",
    "        A = tf.sigmoid(Z)\n",
    "        sess = tf.Session()\n",
    "        prob = sess.run(A)\n",
    "        return prob>threshold\n",
    "    def predict_proba(self,x):\n",
    "        X_test = tf.constant(x.T,dtype=tf.float32,name=\"X_test\")\n",
    "        Z = tf.matmul(tf.transpose(self.W),X_test) + self.b\n",
    "        A = tf.sigmoid(Z)\n",
    "        sess = tf.Session()\n",
    "        prob = sess.run(A)\n",
    "        return prob\n",
    "    def scores(self,x):\n",
    "        X_test = tf.constant(x.T,dtype=tf.float32,name=\"X_test\")\n",
    "        Z = tf.matmul(tf.transpose(self.W),X_test) + self.b\n",
    "        A = tf.sigmoid(Z)\n",
    "        sess = tf.Session()\n",
    "        best_scores = sess.run(Z)\n",
    "        return best_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 cost = 0.7122419\n",
      "Epoch 100 cost = 0.51594085\n",
      "Epoch 200 cost = 0.40080333\n",
      "Epoch 300 cost = 0.32888138\n",
      "Epoch 400 cost = 0.2806491\n",
      "Epoch 500 cost = 0.24628246\n",
      "Epoch 600 cost = 0.22058849\n",
      "Epoch 700 cost = 0.20063834\n",
      "Epoch 800 cost = 0.18467644\n",
      "Epoch 900 cost = 0.17159346\n"
     ]
    }
   ],
   "source": [
    "logit.fit(x,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0097692 ,  1.160053  ,  2.2222908 ,  2.2071369 ,  2.540888  ,\n",
       "         2.3283665 ,  3.0265458 ,  1.9946156 ,  2.1768298 ,  1.4331893 ,\n",
       "         1.7820939 ,  2.5105805 ,  1.4180355 ,  2.7079484 ,  1.5695722 ,\n",
       "         2.9200997 ,  2.3283665 ,  2.0097692 ,  1.2812824 ,  2.829178  ,\n",
       "         0.96268505,  2.5560417 ,  3.5728183 ,  1.4634966 ,  2.5105805 ,\n",
       "         0.90207046,  1.9946156 ,  1.7517865 ,  1.4786502 ,  2.2222908 ,\n",
       "         1.6911718 ,  0.96268505,  3.3906043 ,  2.8897927 ,  1.4331893 ,\n",
       "         1.4483429 ,  0.9778388 ,  1.4331893 ,  2.449966  ,  1.7366328 ,\n",
       "         2.2677517 ,  0.28002936,  2.9962387 ,  2.2677517 ,  2.829178  ,\n",
       "         1.4180355 ,  2.829178  ,  2.4802732 ,  2.0400765 ,  1.7214792 ,\n",
       "        -3.711309  , -2.1634135 , -3.7264628 , -2.2997968 , -3.5139413 ,\n",
       "        -1.4500805 , -1.6322947 , -0.4787646 , -3.4987876 , -0.4333037 ,\n",
       "        -1.8292925 , -1.4197731 , -3.8628461 , -2.2088747 , -0.9189616 ,\n",
       "        -3.2104979 , -0.6458253 , -1.9811994 , -4.3788114 , -2.0115068 ,\n",
       "        -0.8735005 , -2.4820108 , -3.8173847 , -2.4820108 , -2.9828224 ,\n",
       "        -3.2256515 , -4.287889  , -3.4836342 , -1.950892  , -1.9963531 ,\n",
       "        -2.0266602 , -2.0266602 , -1.9811994 , -2.4971647 , -0.12986007,\n",
       "        -0.58521056, -3.2104979 , -4.3636575 , -0.6458253 , -1.7535241 ,\n",
       "        -1.4803878 , -1.9357383 , -2.2543356 , -1.0098836 , -1.4652343 ,\n",
       "        -0.90380794, -1.1769443 , -2.4668572 , -0.7215936 , -1.4500805 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.scores(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.88181895, 0.76134235, 0.9022334 , 0.9008886 , 0.926959  ,\n",
       "        0.9111993 , 0.95375913, 0.8802306 , 0.89814943, 0.8073977 ,\n",
       "        0.85595524, 0.9248802 , 0.8050303 , 0.9374941 , 0.8277226 ,\n",
       "        0.9488312 , 0.9111993 , 0.88181895, 0.782668  , 0.9442323 ,\n",
       "        0.72365904, 0.9279784 , 0.9726901 , 0.8120669 , 0.9248802 ,\n",
       "        0.71137476, 0.8802306 , 0.852178  , 0.8143686 , 0.9022334 ,\n",
       "        0.84437823, 0.72365904, 0.9674096 , 0.94733953, 0.8073977 ,\n",
       "        0.8097432 , 0.7266792 , 0.8073977 , 0.9205589 , 0.8502589 ,\n",
       "        0.9061708 , 0.5695534 , 0.9524039 , 0.9061708 , 0.9442323 ,\n",
       "        0.8050303 , 0.9442323 , 0.9227473 , 0.8849411 , 0.84831923,\n",
       "        0.02386218, 0.10308442, 0.02351174, 0.09113979, 0.02891815,\n",
       "        0.18998918, 0.16351627, 0.38254392, 0.02934675, 0.39333773,\n",
       "        0.13832258, 0.19469716, 0.02057586, 0.09895637, 0.28516954,\n",
       "        0.03877258, 0.3439309 , 0.12119104, 0.01238494, 0.11800007,\n",
       "        0.29452646, 0.07712895, 0.02151227, 0.07712895, 0.04820796,\n",
       "        0.03821174, 0.01354782, 0.02978149, 0.12445613, 0.11958636,\n",
       "        0.11643206, 0.11643206, 0.12119104, 0.07605718, 0.46758053,\n",
       "        0.3577345 , 0.03877258, 0.01257168, 0.3439309 , 0.14760326,\n",
       "        0.18536885, 0.1261168 , 0.09497614, 0.2670026 , 0.18766807,\n",
       "        0.2882686 , 0.23560207, 0.07821451, 0.32704213, 0.18998916]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.predict_proba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_hidden(x,Y,hidden_neurons,n_inputs):\n",
    "    W1 = tf.Variable(np.random.randn(hidden_neurons,n_inputs), dtype=tf.float32,name = 'W1')#shape = (n_inputs,1)\n",
    "    b1 = tf.Variable(tf.zeros([hidden_neurons,1]), dtype=tf.float32,name='b1')\n",
    "    X = tf.constant(x.T,dtype=tf.float32,name=\"X\")\n",
    "    y = tf.constant(Y.reshape(1,x.shape[0]),dtype=tf.float32,name=\"y\")\n",
    "    Z = tf.matmul(W1,X) + b1\n",
    "    A = tf.nn.relu(Z)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    return sess.run(W1),sess.run(b1),sess.run(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights,bias,activations = input_hidden(x,Y,hidden_neurons=2,n_inputs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_output(hidden_activations,Y,n_outputs,hidden_neurons):\n",
    "    W2 = tf.Variable(np.random.randn(n_outputs,hidden_neurons), dtype=tf.float32,name = 'W2')#shape = (n_inputs,1)\n",
    "    b2 = tf.Variable(tf.zeros([n_outputs,1]), dtype=tf.float32,name='b2')\n",
    "    hidden_activations = tf.constant(hidden_activations,dtype=tf.float32,name=\"hidden_activations\")\n",
    "    y = tf.constant(Y.reshape(1,x.shape[0]),dtype=tf.float32,name=\"y\")\n",
    "    Z = tf.matmul(W2,hidden_activations) + b2\n",
    "    A = tf.sigmoid(Z)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    return sess.run(W2),sess.run(b2),sess.run(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights,bias,logits = hidden_output(activations,Y,n_outputs=1,hidden_neurons=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(Y,z):\n",
    "    y = tf.constant(Y.reshape(1,x.shape[0]),dtype=tf.float32,name=\"y\")\n",
    "    Z = tf.constant(z.reshape(1,x.shape[0]),dtype=tf.float32,name=\"Z\")\n",
    "    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Z,  labels = y))\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    return sess.run(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0209799"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost(Y,logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self,n_epochs=1000,n_inputs=2,hidden_neurons=2,n_outputs=1,learning_rate=0.01):\n",
    "        self.epochs = n_epochs\n",
    "        self.lr = learning_rate\n",
    "        self.W1 = tf.Variable(np.random.randn(hidden_neurons,n_inputs), dtype=tf.float32,name = 'W1')#shape = (n_inputs,1)\n",
    "        self.b1 = tf.Variable(tf.zeros([hidden_neurons,1]), dtype=tf.float32,name='b1')\n",
    "        self.W2 = tf.Variable(np.random.randn(n_outputs,hidden_neurons), dtype=tf.float32,name = 'W2')#shape = (n_inputs,1)\n",
    "        self.b2 = tf.Variable(tf.zeros([n_outputs,1]), dtype=tf.float32,name='b2')\n",
    "    def fit(self,x,Y):\n",
    "        X = tf.constant(x.T,dtype=tf.float32,name=\"X\")\n",
    "        y = tf.constant(Y.reshape(1,x.shape[0]),dtype=tf.float32,name=\"y\")\n",
    "        Z1 = tf.add(tf.matmul(self.W1,X),self.b1)\n",
    "        A1 = tf.nn.relu(Z1)\n",
    "        Z2 = tf.add(tf.matmul(self.W2,A1),self.b2)\n",
    "        #Z = tf.constant(Z2,dtype=tf.float32,name=\"Z\")\n",
    "        cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Z2,  labels = y))\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate = self.lr)\n",
    "        training_op = optimizer.minimize(cost)\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess = tf.Session()\n",
    "        sess.run(init)\n",
    "        for epoch in range(self.epochs):\n",
    "            if epoch % 100 == 0:\n",
    "                print(\"Epoch\", epoch, \"cost =\", sess.run(cost))\n",
    "            sess.run(training_op)\n",
    "        self.W1 = sess.run(self.W1)\n",
    "        self.b1 = sess.run(self.b1)\n",
    "        self.W2 = sess.run(self.W2)\n",
    "        self.b2 = sess.run(self.b2)\n",
    "    def predict(self,x,threshold=0.5):\n",
    "        X_test = tf.constant(x.T,dtype=tf.float32,name=\"X_test\")\n",
    "        Z1 = tf.add(tf.matmul(self.W1,X_test),self.b1)\n",
    "        A1 = tf.nn.relu(Z1)\n",
    "        Z2 = tf.add(tf.matmul(self.W2,A1),self.b2)\n",
    "        A2 = tf.sigmoid(Z2)\n",
    "        sess = tf.Session()\n",
    "        prob = sess.run(A2)\n",
    "        return prob>threshold\n",
    "    def predict_proba(self,x):\n",
    "        X_test = tf.constant(x.T,dtype=tf.float32,name=\"X_test\")\n",
    "        Z1 = tf.add(tf.matmul(self.W1,X_test),self.b1)\n",
    "        A1 = tf.nn.relu(Z1)\n",
    "        Z2 = tf.add(tf.matmul(self.W2,A1),self.b2)\n",
    "        A2 = tf.sigmoid(Z2)\n",
    "        sess = tf.Session()\n",
    "        prob = sess.run(A2)\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 cost = 0.87532973\n",
      "Epoch 100 cost = 0.6549813\n",
      "Epoch 200 cost = 0.52948296\n",
      "Epoch 300 cost = 0.4295184\n",
      "Epoch 400 cost = 0.3434387\n",
      "Epoch 500 cost = 0.27722684\n",
      "Epoch 600 cost = 0.22775063\n",
      "Epoch 700 cost = 0.18921483\n",
      "Epoch 800 cost = 0.15910025\n",
      "Epoch 900 cost = 0.1346353\n"
     ]
    }
   ],
   "source": [
    "mlp.fit(x,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.predict(x,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9536948 , 0.87792635, 0.9696456 , 0.97019684, 0.9774809 ,\n",
       "        0.96550095, 0.98977685, 0.95452213, 0.9712704 , 0.91183525,\n",
       "        0.9311881 , 0.9782979 , 0.9133426 , 0.98615927, 0.89717156,\n",
       "        0.98204297, 0.96550095, 0.9536948 , 0.8607781 , 0.9839368 ,\n",
       "        0.8198221 , 0.9770611 , 0.9950305 , 0.90874946, 0.9782979 ,\n",
       "        0.83071834, 0.95452213, 0.9335707 , 0.9071703 , 0.9696456 ,\n",
       "        0.9381073 , 0.8198221 , 0.9920197 , 0.9826974 , 0.91183525,\n",
       "        0.9103043 , 0.81701386, 0.91183525, 0.97984594, 0.934733  ,\n",
       "        0.9679319 , 0.7228374 , 0.9901523 , 0.9679319 , 0.9839368 ,\n",
       "        0.9133426 , 0.9839368 , 0.979086  , 0.95199686, 0.93587637,\n",
       "        0.03433632, 0.0858851 , 0.03644367, 0.14073408, 0.05080245,\n",
       "        0.16354051, 0.1088244 , 0.4484467 , 0.0479061 , 0.40641016,\n",
       "        0.21415305, 0.14734039, 0.06185429, 0.10158838, 0.2026235 ,\n",
       "        0.04969048, 0.23777513, 0.13075982, 0.04552011, 0.14544788,\n",
       "        0.17433305, 0.09280181, 0.05193796, 0.09280181, 0.0650381 ,\n",
       "        0.05268876, 0.03187605, 0.04516698, 0.11735132, 0.13793974,\n",
       "        0.15329206, 0.15329206, 0.13075982, 0.09813276, 0.48085788,\n",
       "        0.18429774, 0.04969048, 0.04291128, 0.23777513, 0.16675317,\n",
       "        0.18114343, 0.11110497, 0.11978658, 0.2690428 , 0.17216387,\n",
       "        0.19282986, 0.17771266, 0.08773227, 0.31827933, 0.16354051]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.predict_proba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "final =  pd.read_csv(\"final.csv\",sep='\\t')\n",
    "dat = final.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>unknown -2</th>\n",
       "      <th>duly paid</th>\n",
       "      <th>unknown 0</th>\n",
       "      <th>delay by one month</th>\n",
       "      <th>delay by two month</th>\n",
       "      <th>delay by three month</th>\n",
       "      <th>delay by four months and above</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>Previous_pmt_Sum</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Mean_bill_Amount</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20000</td>\n",
       "      <td>689</td>\n",
       "      <td>24</td>\n",
       "      <td>1284.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120000</td>\n",
       "      <td>5000</td>\n",
       "      <td>26</td>\n",
       "      <td>2846.166667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90000</td>\n",
       "      <td>11018</td>\n",
       "      <td>34</td>\n",
       "      <td>16942.166667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50000</td>\n",
       "      <td>8388</td>\n",
       "      <td>37</td>\n",
       "      <td>38555.666667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50000</td>\n",
       "      <td>59049</td>\n",
       "      <td>57</td>\n",
       "      <td>18223.166667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEX  EDUCATION  MARRIAGE  unknown -2  duly paid  unknown 0  \\\n",
       "0    2          2         1           1          1          0   \n",
       "1    2          2         2           0          1          1   \n",
       "2    2          2         2           0          0          1   \n",
       "3    2          2         1           0          0          1   \n",
       "4    1          2         1           0          1          1   \n",
       "\n",
       "   delay by one month  delay by two month  delay by three month  \\\n",
       "0                   0                   1                     0   \n",
       "1                   0                   1                     0   \n",
       "2                   0                   0                     0   \n",
       "3                   0                   0                     0   \n",
       "4                   0                   0                     0   \n",
       "\n",
       "   delay by four months and above  LIMIT_BAL  Previous_pmt_Sum  AGE  \\\n",
       "0                               0      20000               689   24   \n",
       "1                               0     120000              5000   26   \n",
       "2                               0      90000             11018   34   \n",
       "3                               0      50000              8388   37   \n",
       "4                               0      50000             59049   57   \n",
       "\n",
       "   Mean_bill_Amount  default payment next month  \n",
       "0       1284.000000                           1  \n",
       "1       2846.166667                           1  \n",
       "2      16942.166667                           0  \n",
       "3      38555.666667                           0  \n",
       "4      18223.166667                           0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = dat.copy()\n",
    "dat = dat.loc[dat['Previous_pmt_Sum']<=73739.125]\n",
    "dat = dat.loc[dat['LIMIT_BAL']<=525000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing a function to randomly sample equal no. of samples of defaulter and non defaulter for the training set.\n",
    "#The remaining samples can be kept for the trainig set.\n",
    "#0 - majority , 1 - minority\n",
    "def train_test_split(data,target_column,majorityclass_samples,minorityclass_samples):\n",
    "    x = majorityclass_samples#no of samples for majority class\n",
    "    y = minorityclass_samples#no of samples for minority class\n",
    "    dat_0 = dat.loc[dat[target_column]==0,:]\n",
    "    dat_1 = dat.loc[dat[target_column]==1,:]\n",
    "    dat_0.index = np.arange(len(dat_0))\n",
    "    dat_1.index = np.arange(len(dat_1))\n",
    "    nodefault_index_train = np.random.permutation(len(dat_0))[:x]\n",
    "    nodefault_index_test = np.random.permutation(len(dat_0))[x:]\n",
    "    default_index_train = np.random.permutation(len(dat_1))[:y]\n",
    "    default_index_test = np.random.permutation(len(dat_1))[y:]\n",
    "    nodefault_train = dat_0.loc[nodefault_index_train]\n",
    "    nodefault_test = dat_0.loc[nodefault_index_test]\n",
    "    default_train = dat_1.loc[default_index_train]\n",
    "    default_test = dat_1.loc[default_index_test]\n",
    "    train = pd.concat([nodefault_train,default_train])\n",
    "    test = pd.concat([nodefault_test,default_test])\n",
    "    train.index = np.arange(len(train))\n",
    "    test.index = np.arange(len(test))\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert categorical columns to one hot array\n",
    "def convert_to_onehotarray(dat,target_columns):\n",
    "    encoder = LabelBinarizer()\n",
    "    dat = dat[target_columns]\n",
    "    d={}\n",
    "    l=[]\n",
    "    d_attr = {}\n",
    "    for i in target_columns:\n",
    "        d[i] = encoder.fit_transform(dat[i])\n",
    "        d_attr[i] = list(encoder.classes_)\n",
    "        l.append(d[i])\n",
    "    return np.concatenate(l,axis=1),d_attr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining categorical and continous columns to form a array ready for training.\n",
    "def combine_cat_num(dat,cat_attributes,num_attributes):\n",
    "    cat,encoder_attributes = convert_to_onehotarray(dat,cat_attributes)\n",
    "    d = {}\n",
    "    l = []\n",
    "    for i in num_attributes:\n",
    "        d[i] = dat[i].values.reshape(len(dat[i]),1)\n",
    "        l.append(d[i])\n",
    "    num = np.concatenate(l,axis=1)\n",
    "    final = np.concatenate([cat,num],axis=1)\n",
    "    return final,encoder_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_attributes = ['SEX', 'EDUCATION', 'MARRIAGE', 'unknown -2', 'duly paid', 'unknown 0','delay by one month', 'delay by two month', 'delay by three month','delay by four months and above']\n",
    "num_attributes = ['LIMIT_BAL', 'Previous_pmt_Sum','AGE','Mean_bill_Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = train_test_split(dat,'default payment next month',5000,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshuffling the training and testing set \n",
    "train = train.loc[np.random.permutation(len(train))]\n",
    "test = test.loc[np.random.permutation(len(test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,train_cat_attr = combine_cat_num(train,cat_attributes,num_attributes)\n",
    "train_y = train.iloc[:,-1]\n",
    "test_x,test_cat_attr = combine_cat_num(test,cat_attributes,num_attributes)\n",
    "test_y = test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(X):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    return np.c_[train_x[:,:15],scaler.fit_transform(train_x[:,-4:])]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = transform(train_x)\n",
    "Y = np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 19)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(n_epochs=10000,n_inputs=19,hidden_neurons=15,n_outputs=1,learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 cost = 2.500333\n",
      "Epoch 100 cost = 0.70150137\n",
      "Epoch 200 cost = 0.65714127\n",
      "Epoch 300 cost = 0.64078236\n",
      "Epoch 400 cost = 0.6324878\n",
      "Epoch 500 cost = 0.6272386\n",
      "Epoch 600 cost = 0.62328327\n",
      "Epoch 700 cost = 0.6200538\n",
      "Epoch 800 cost = 0.61731535\n",
      "Epoch 900 cost = 0.6148458\n",
      "Epoch 1000 cost = 0.6126961\n",
      "Epoch 1100 cost = 0.6107268\n",
      "Epoch 1200 cost = 0.60896665\n",
      "Epoch 1300 cost = 0.6073298\n",
      "Epoch 1400 cost = 0.6057739\n",
      "Epoch 1500 cost = 0.60435957\n",
      "Epoch 1600 cost = 0.60304445\n",
      "Epoch 1700 cost = 0.6018725\n",
      "Epoch 1800 cost = 0.6008398\n",
      "Epoch 1900 cost = 0.5999019\n",
      "Epoch 2000 cost = 0.5990423\n",
      "Epoch 2100 cost = 0.5982249\n",
      "Epoch 2200 cost = 0.5974679\n",
      "Epoch 2300 cost = 0.59677196\n",
      "Epoch 2400 cost = 0.5961537\n",
      "Epoch 2500 cost = 0.59559715\n",
      "Epoch 2600 cost = 0.59505826\n",
      "Epoch 2700 cost = 0.5945503\n",
      "Epoch 2800 cost = 0.5940752\n",
      "Epoch 2900 cost = 0.5936162\n",
      "Epoch 3000 cost = 0.5931951\n",
      "Epoch 3100 cost = 0.59278595\n",
      "Epoch 3200 cost = 0.59236616\n",
      "Epoch 3300 cost = 0.5919771\n",
      "Epoch 3400 cost = 0.5916274\n",
      "Epoch 3500 cost = 0.5913124\n",
      "Epoch 3600 cost = 0.5910268\n",
      "Epoch 3700 cost = 0.59075665\n",
      "Epoch 3800 cost = 0.5904988\n",
      "Epoch 3900 cost = 0.5902351\n",
      "Epoch 4000 cost = 0.5899373\n",
      "Epoch 4100 cost = 0.5896212\n",
      "Epoch 4200 cost = 0.58934075\n",
      "Epoch 4300 cost = 0.5890917\n",
      "Epoch 4400 cost = 0.58883137\n",
      "Epoch 4500 cost = 0.5885777\n",
      "Epoch 4600 cost = 0.58831453\n",
      "Epoch 4700 cost = 0.58808464\n",
      "Epoch 4800 cost = 0.5878875\n",
      "Epoch 4900 cost = 0.58769923\n",
      "Epoch 5000 cost = 0.58750105\n",
      "Epoch 5100 cost = 0.58732074\n",
      "Epoch 5200 cost = 0.58714545\n",
      "Epoch 5300 cost = 0.586969\n",
      "Epoch 5400 cost = 0.58679944\n",
      "Epoch 5500 cost = 0.58662784\n",
      "Epoch 5600 cost = 0.5864597\n",
      "Epoch 5700 cost = 0.5862858\n",
      "Epoch 5800 cost = 0.58610696\n",
      "Epoch 5900 cost = 0.58592576\n",
      "Epoch 6000 cost = 0.5857671\n",
      "Epoch 6100 cost = 0.5856101\n",
      "Epoch 6200 cost = 0.58546203\n",
      "Epoch 6300 cost = 0.58531415\n",
      "Epoch 6400 cost = 0.585167\n",
      "Epoch 6500 cost = 0.58501875\n",
      "Epoch 6600 cost = 0.5848751\n",
      "Epoch 6700 cost = 0.58473206\n",
      "Epoch 6800 cost = 0.58458644\n",
      "Epoch 6900 cost = 0.584445\n",
      "Epoch 7000 cost = 0.58431304\n",
      "Epoch 7100 cost = 0.58418787\n",
      "Epoch 7200 cost = 0.5840669\n",
      "Epoch 7300 cost = 0.58394766\n",
      "Epoch 7400 cost = 0.5838305\n",
      "Epoch 7500 cost = 0.5837144\n",
      "Epoch 7600 cost = 0.583603\n",
      "Epoch 7700 cost = 0.5834914\n",
      "Epoch 7800 cost = 0.5833821\n",
      "Epoch 7900 cost = 0.5832754\n",
      "Epoch 8000 cost = 0.5831693\n",
      "Epoch 8100 cost = 0.5830624\n",
      "Epoch 8200 cost = 0.5829616\n",
      "Epoch 8300 cost = 0.5828654\n",
      "Epoch 8400 cost = 0.5827752\n",
      "Epoch 8500 cost = 0.5826842\n",
      "Epoch 8600 cost = 0.5825906\n",
      "Epoch 8700 cost = 0.5824963\n",
      "Epoch 8800 cost = 0.5824071\n",
      "Epoch 8900 cost = 0.58232045\n",
      "Epoch 9000 cost = 0.58223337\n",
      "Epoch 9100 cost = 0.5821481\n",
      "Epoch 9200 cost = 0.5820659\n",
      "Epoch 9300 cost = 0.5819876\n",
      "Epoch 9400 cost = 0.5819119\n",
      "Epoch 9500 cost = 0.58183914\n",
      "Epoch 9600 cost = 0.58177036\n",
      "Epoch 9700 cost = 0.5817027\n",
      "Epoch 9800 cost = 0.58163637\n",
      "Epoch 9900 cost = 0.58157176\n"
     ]
    }
   ],
   "source": [
    "mlp.fit(x,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = np.where(mlp.predict(x,0.5)==False,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual  Predicted\n",
       "0       1          1\n",
       "1       1          0\n",
       "2       1          1\n",
       "3       0          0\n",
       "4       1          1"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.DataFrame(np.c_[y_actual.reshape(10000,1),y_predicted.reshape(10000,1)])\n",
    "d.columns = ['Actual','Predicted']\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5000\n",
       "0    5000\n",
       "Name: Actual, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['Actual'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5386\n",
       "1    4614\n",
       "Name: Predicted, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['Predicted'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(train_y,predicted_train_y):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    a = pd.DataFrame(confusion_matrix(train_y,predicted_train_y))\n",
    "    a.columns = ['predicted_0','predicted_1']\n",
    "    a.index = ['Actual_0','Actual_1']\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_0</th>\n",
       "      <th>predicted_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual_0</th>\n",
       "      <td>3706</td>\n",
       "      <td>1294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual_1</th>\n",
       "      <td>1680</td>\n",
       "      <td>3320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted_0  predicted_1\n",
       "Actual_0         3706         1294\n",
       "Actual_1         1680         3320"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(d['Actual'].values,d['Predicted'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_f1(actuall_class,predicted_class):\n",
    "    from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "    prec = precision_score(actuall_class,predicted_class)\n",
    "    rec =  recall_score(actuall_class,predicted_class)\n",
    "    f1 = f1_score(actuall_class,predicted_class)\n",
    "    return print(\"precsion-\" + str(prec),\" Recall-\" + str(rec),\" F1 score-\" + str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precsion-0.7195491980927612  Recall-0.664  F1 score-0.6906594549615145\n"
     ]
    }
   ],
   "source": [
    "precision_recall_f1(d['Actual'].values,d['Predicted'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
